{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fad_score\n",
    "\n",
    "> Produce FAD score based on files of embeddings of real and fake data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ FAD = || \\mu_r - \\mu_f ||^2 + tr\\left(\\Sigma_r + \\Sigma_f - 2 \\sqrt{\\Sigma_r \\Sigma_f}\\right)$$\n",
    "\n",
    "The embeddings are small enough that this can typically be run on a single processor, on a CPU. However, all the supporting code is GPU-friendly if so desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp fad_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch \n",
    "import argparse\n",
    "from fad_pytorch.sqrtm import sqrtm\n",
    "from aeiou.core import fast_scandir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_embeddings(emb_path='real_emb_clap/', debug=False):\n",
    "    \"reads any .pt files in emb_path and concatenates them into one tensor\"\n",
    "    if debug: print(\"searching in \",emb_path) \n",
    "    _, file_list = fast_scandir(emb_path, ['pt'])\n",
    "    if  file_list == []:\n",
    "        _, file_list = fast_scandir('/fsx/shawley/code/fad_pytorch/'+emb_path, ['pt']) # yea, cheap hack just for my testing in nbs/ dir\n",
    "    assert file_list != []\n",
    "    embeddings = []\n",
    "    for file_path in file_list:\n",
    "        emb_batch = torch.load(file_path, map_location='cpu') \n",
    "        embeddings.append(emb_batch)\n",
    "    return torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# lil test of that\n",
    "e = read_embeddings()\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def calc_mu_sigma(emb): \n",
    "    \"calculates mean and covariance matrix of batched embeddings\"\n",
    "    mu = torch.mean(emb, axis=0)\n",
    "    sigma = torch.cov(emb.T)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512]), torch.Size([512, 512]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "# quick test:\n",
    "x = torch.rand(32,512) \n",
    "mu, sigma = calc_mu_sigma(x) \n",
    "mu.shape, sigma.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calc_score(real_emb_path, # where real embeddings are stored\n",
    "               fake_emb_path, # where fake embeddings are stored\n",
    "               method='maji', # sqrtm calc method: 'maji'|'li'\n",
    "               debug=False\n",
    "               ): \n",
    "    print(f\"Calculating FAD score for files in {real_emb_path}/ vs. {fake_emb_path}/\")\n",
    "    emb_real = read_embeddings(emb_path=real_emb_path, debug=debug)\n",
    "    emb_fake = read_embeddings(emb_path=fake_emb_path, debug=debug)\n",
    "    if debug: print(emb_real.shape, emb_fake.shape)\n",
    "    \n",
    "    mu_real, sigma_real = calc_mu_sigma(emb_real) \n",
    "    mu_fake, sigma_fake = calc_mu_sigma(emb_fake) \n",
    "    if debug:\n",
    "        print(\"mu_real.shape, sigma_real.shape =\",mu_real.shape, sigma_real.shape)\n",
    "        print(\"mu_fake.shape, sigma_fake.shape =\",mu_fake.shape, sigma_fake.shape)\n",
    "    \n",
    "    mu_diff = mu_real - mu_fake\n",
    "    if debug:\n",
    "        print(\"mu_diff = \",mu_diff) \n",
    "        score1 = mu_diff.dot(mu_diff)\n",
    "        print(\"score1: mu_diff.dot(mu_diff) = \",score1)\n",
    "        score2 = torch.trace(sigma_real)\n",
    "        print(\"score2: torch.trace(sigma_real) = \", score2)\n",
    "        score3 = torch.trace(sigma_fake)\n",
    "        print(\"score3: torch.trace(sigma_fake) = \",score3)\n",
    "        score_p = sqrtm( torch.matmul( sigma_real, sigma_fake) )\n",
    "        print(\"score_p.shape (matmul) = \",score_p.shape) \n",
    "        score4 = -2* torch.trace ( torch.real ( sqrtm( torch.matmul( sigma_real, sigma_fake) , method=method ) ) )\n",
    "        print(\"score4 (-2*tr(sqrtm(matmul(sigma_r sigma_f))))  = \",score4) \n",
    "        score = score1 + score2 + score3 + score4\n",
    "    score = mu_diff.dot(mu_diff) + torch.trace(sigma_real) + torch.trace(sigma_fake) -2* torch.trace ( torch.real ( sqrtm( torch.matmul( sigma_real, sigma_fake), method=method  ) ) )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the score function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FAD score for files in real_emb_clap// vs. fake_emb_clap//\n",
      "tensor(0.0951)\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "score = calc_score( 'real_emb_clap/', 'fake_emb_clap/', method='maji')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try sending using the exact same data for both distributions: Do we get zero? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating FAD score for files in real_emb_clap// vs. real_emb_clap//\n",
      "searching in  real_emb_clap/\n",
      "searching in  real_emb_clap/\n",
      "torch.Size([256, 512]) torch.Size([256, 512])\n",
      "mu_real.shape, sigma_real.shape = torch.Size([512]) torch.Size([512, 512])\n",
      "mu_fake.shape, sigma_fake.shape = torch.Size([512]) torch.Size([512, 512])\n",
      "mu_diff =  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "score1: mu_diff.dot(mu_diff) =  tensor(0.)\n",
      "score2: torch.trace(sigma_real) =  tensor(0.4448)\n",
      "score3: torch.trace(sigma_fake) =  tensor(0.4448)\n",
      "score_p.shape (matmul) =  torch.Size([512, 512])\n",
      "score4 (-2*tr(sqrtm(matmul(sigma_r sigma_f))))  =  tensor(-0.8888)\n",
      "tensor(0.0008)\n"
     ]
    }
   ],
   "source": [
    "score = calc_score( 'real_emb_clap/', 'real_emb_clap/', method='maji', debug=True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so not zero, but small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of fad_pytorch.sqrtm failed: Traceback (most recent call last):\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 273, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 496, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 345, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 345, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 345, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 393, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/fsx/shawley/envs_sm/aa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 345, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def main(): \n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('real_emb_path', help='Path of files of embeddings of real data', default='real_emb_clap/')\n",
    "    parser.add_argument('fake_emb_path', help='Path of files of embeddings of fake data', default='fake_emb_clap/')\n",
    "    parser.add_argument('-d','--debug', action='store_true', help='Enable debugging')\n",
    "    parser.add_argument('-m','--method', default='maji', help='Method for sqrtm calculation: \"maji\" or \"li\" ')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    score = calc_score( args.real_emb_path, args.fake_emb_path, method=args.method, debug=args.debug )\n",
    "    print(\"FAD score = \",score.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == '__main__' and \"get_ipython\" not in dir():\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa",
   "language": "python",
   "name": "aa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
